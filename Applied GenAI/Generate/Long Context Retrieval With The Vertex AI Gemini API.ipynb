{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37b4076",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FGenerate&file=Long+Context+Retrieval+With+The+Vertex+AI+Gemini+API.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FGenerate%2FLong%2520Context%2520Retrieval%2520With%2520The%2520Vertex%2520AI%2520Gemini%2520API.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f1a5be-feee-4a70-a927-8abfbd4cc98c",
   "metadata": {},
   "source": [
    "# Long Context Retrieval With The Vertex AI Gemini API\n",
    "\n",
    "**Retrieval - the task of retrieving information as context for an LLM**, like the Gemini family on Vertex AI. Retrieval augmented generation (RAG) is the task of retrieving relevant context and then providing it along with the prompt to the LLM. \n",
    "\n",
    "[Long context](https://cloud.google.com/vertex-ai/generative-ai/docs/long-context) is a way of providing full-length sources to the LLM, which can then perform its own retrieval.  Gemini 1.5 Flash (1M) and Gemini 1.5 Pro (2M) have incredible input context windows (1M and 2M tokens respectively) and have shown [near-perfect retrieval of > 99%](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf).\n",
    "\n",
    "For a complete overview of the Gemini API, check out the companion workflow [Vertex AI Gemini API](./Vertex%20AI%20Gemini%20API.ipynb).\n",
    "\n",
    "**Use Case Exploration**\n",
    "\n",
    "Buying a home usually involves borrowing money from a lending institution, typically through a mortgage secured by the home's value. But how do these institutions manage the risks associated with such large loans, and how are lending standards established?\n",
    "\n",
    "In the United States, two government-sponsored enterprises (GSEs) play a vital role in the housing market:\n",
    "- Federal National Mortgage Association ([Fannie Mae](https://www.fanniemae.com/))\n",
    "- Federal Home Loan Mortgage Corporation ([Freddie Mac](https://www.freddiemac.com/))\n",
    "\n",
    "These GSEs purchase mortgages from lenders, enabling those lenders to offer more loans. This process also allows Fannie Mae and Freddie Mac to set standards for mortgages, ensuring they are responsible and borrowers are more likely to repay them. This system makes homeownership more affordable and stabilizes the housing market by maintaining a steady flow of liquidity for lenders and keeping interest rates controlled.\n",
    "\n",
    "However, navigating the complexities of these GSEs and their extensive servicing guides can be challenging. What if you could directly query these guides and get precise answers without needing to design a complex RAG architecture?\n",
    "\n",
    "This workflow leverages the long context capabilities of Vertex AI Gemini models and the efficiency of context caching to provide low-latency and cost-effective access to these comprehensive documents. Explore the implementation below!\n",
    "\n",
    "**References**\n",
    "- [Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach](https://arxiv.org/pdf/2407.16833)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ece663-3016-4501-aa23-8a88c530067f",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c40dc09-e248-402d-a350-5de4f2c00f49",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d1d8ef-591c-4f22-8e3b-95d1ea01485e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751709b-5c77-4a9d-8db7-59a1e31a57f5",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfb1c54-be62-4842-9134-63296ccf5461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.69.0'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage'),\n",
    "    ('fitz', 'pymupdf'),\n",
    "    ('requests', 'requests')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767959a6-0f26-426c-b8d5-ee2d9aebba9b",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6dca7d-8e41-41a3-bcf8-778a94a139b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e79a0d-00f1-4f24-b7c6-654afc2a01dd",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e226fcb9-6300-44ff-be3f-969b4e5ff8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615f583-88f8-4d42-b1e4-f5c328fd6470",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc2c040-7f2d-4bc8-af61-e37e9742bbb1",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7450a4-b673-43c6-8073-09254f159e82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5230593b-33a8-4b59-afd4-8ffb4e319715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'long-context'\n",
    "\n",
    "GCS_BUCKET = PROJECT_ID # change to Bucket name if not the same as the Project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cfe0fe-2965-474a-be2b-d2b6ec610390",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "efcba1ba-2e39-40b9-8464-5851121c62ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python standard library imports:\n",
    "import os, io, base64, json, datetime\n",
    "\n",
    "# package imports\n",
    "from IPython.display import Markdown\n",
    "import IPython.display\n",
    "import fitz #pymupdf\n",
    "import requests\n",
    "\n",
    "# vertex ai imports\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "\n",
    "# preview imports for vertex ai api:\n",
    "from vertexai.preview import caching\n",
    "import vertexai.preview.generative_models\n",
    "import vertexai.preview.batch_prediction\n",
    "\n",
    "# google cloud imports\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81cc0fdc-2b00-4cb9-b789-9543f51bc988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.69.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12939dcc-9376-424f-bd8a-db25e14bc4ef",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb530fa-7633-46ec-ae22-2e4a5e81e99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bucket = gcs.bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d99693-f3d8-48d1-80f5-619d01301353",
   "metadata": {},
   "source": [
    "---\n",
    "## Gemini Models\n",
    "\n",
    "Select one of the [supported Gemini models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models) and read more about the characteristics of each [here](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff7672-a1e8-4844-a1b1-4daffef1441e",
   "metadata": {},
   "source": [
    "### Setup Model\n",
    "\n",
    "Here the [Gemini 1.5 Flash model with version 002](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash) is selected. It has these characteristics (to name a few):\n",
    "- Max Input Tokens: 1,048,576\n",
    "- Max Output Tokens: 8,192\n",
    "- Max image:\n",
    "    - raw size 20MB\n",
    "    - base64 encoded size 7MB\n",
    "    - number per prompt 3000\n",
    "- Max video:\n",
    "    - length 1 hour\n",
    "    - number per prompt 10\n",
    "- Max audio:\n",
    "    - length 8.4 hours\n",
    "    - number per prompt 1\n",
    "- Max PDF:\n",
    "    - size 30 MB\n",
    "- 102 [Languages](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#languages-gemini) for understanding and responding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2afb7060-ab49-44f4-a6d2-bab2805f61ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemini = vertexai.generative_models.GenerativeModel(\"gemini-1.5-pro-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b078403-3e54-4d1d-81d5-d6bd18ec5abc",
   "metadata": {},
   "source": [
    "### **Prompt With Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135842da-0f68-420e-85c6-f1824ce126a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Getting a mortgage is a multi-step process. Here's a general outline of how it works:\n",
       "\n",
       "**1. Check Your Credit Score and History:**\n",
       "\n",
       "* **Obtain your credit report:** Get free copies from AnnualCreditReport.com (the only federally authorized site). Review for errors and dispute any inaccuracies.\n",
       "* **Understand your credit score:**  A higher score generally means better interest rates.  Aim for a score above 620, though higher is always better.\n",
       "\n",
       "**2. Determine How Much You Can Afford:**\n",
       "\n",
       "* **Use online mortgage calculators:** These tools can give you a preliminary estimate based on income, debt, and desired down payment.\n",
       "* **Consider your debt-to-income ratio (DTI):** Lenders look at this closely.  A lower DTI (generally below 43%) is preferred.\n",
       "* **Factor in all housing costs:** Don't just think about the mortgage payment. Include property taxes, homeowner's insurance, and potential HOA fees.\n",
       "\n",
       "**3. Get Pre-Approved for a Mortgage:**\n",
       "\n",
       "* **Shop around with multiple lenders:** Compare interest rates, fees, and loan terms. Don't be afraid to negotiate.\n",
       "* **Provide necessary documentation:** Be prepared to share pay stubs, tax returns, bank statements, and other financial information.\n",
       "* **Receive a pre-approval letter:** This shows sellers you're a serious buyer and strengthens your offer.\n",
       "\n",
       "**4. Find a Real Estate Agent (Optional but Recommended):**\n",
       "\n",
       "* **An agent can help you navigate the home-buying process:** They can help you find properties, negotiate offers, and understand the local market.\n",
       "\n",
       "**5. Shop for a Home:**\n",
       "\n",
       "* **Consider your needs and wants:**  Think about location, size, amenities, and your long-term goals.\n",
       "* **Attend open houses and schedule private showings:** Get a feel for the properties and the neighborhoods.\n",
       "\n",
       "**6. Make an Offer on a Home:**\n",
       "\n",
       "* **Work with your agent to craft a competitive offer:**  Consider the asking price, market conditions, and any contingencies (e.g., home inspection).\n",
       "\n",
       "**7. Get a Home Appraisal:**\n",
       "\n",
       "* **The lender will order an appraisal to determine the fair market value of the property:** This protects both you and the lender.\n",
       "\n",
       "**8. Finalize the Mortgage:**\n",
       "\n",
       "* **The lender will finalize the loan terms and prepare the closing documents:** Review everything carefully before signing.\n",
       "* **Purchase homeowner's insurance:**  This is required by lenders.\n",
       "* **Close on the home:** This is when you sign the final paperwork, pay closing costs, and receive the keys to your new home.\n",
       "\n",
       "\n",
       "**Key Terms to Know:**\n",
       "\n",
       "* **Down payment:** The upfront portion of the home's purchase price that you pay.  A larger down payment typically means a lower interest rate and monthly payment.\n",
       "* **Interest rate:** The cost of borrowing money.\n",
       "* **Loan term:** The length of time you have to repay the loan (e.g., 15 years, 30 years).\n",
       "* **Closing costs:** Fees associated with the mortgage process, including appraisal fees, title insurance, and lender fees.\n",
       "* **Private Mortgage Insurance (PMI):**  If your down payment is less than 20%, you'll likely be required to pay PMI, which protects the lender if you default on the loan.\n",
       "\n",
       "\n",
       "**Tips for a Smoother Process:**\n",
       "\n",
       "* **Save for a down payment:** The more you can save, the better.\n",
       "* **Pay down debt:**  Lowering your DTI can improve your chances of getting approved and securing a favorable interest rate.\n",
       "* **Organize your financial documents:**  Having everything readily available will streamline the application process.\n",
       "* **Ask questions:** Don't hesitate to ask your lender or real estate agent if you're unsure about anything.\n",
       "\n",
       "Getting a mortgage can seem daunting, but by understanding the process and preparing in advance, you can make it a smoother experience. Good luck!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gemini.generate_content('How do I get a mortgage?')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07512b1-9f6e-49db-85c2-92839f425c48",
   "metadata": {},
   "source": [
    "### Retrieve Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "772a322c-83fb-443b-b380-497ea8cdf69f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_url = 'https://guide.freddiemac.com/ci/okcsFattach/get/1002095_2'\n",
    "fannie_url = 'https://singlefamily.fanniemae.com/media/39861/display'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17702779-2554-4d3f-9659-b011d2cd2cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_retrieve = requests.get(freddie_url).content\n",
    "fannie_retrieve = requests.get(fannie_url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff1a3a84-0a5f-4e7b-8358-f1bd182f321f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_doc = fitz.open(stream = freddie_retrieve, filetype = 'pdf')\n",
    "fannie_doc = fitz.open(stream = fannie_retrieve, filetype = 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6f7312d-0b84-4f9b-9ac0-999def72b056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2641, 1180)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freddie_doc.page_count, fannie_doc.page_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284e36d1-86d3-4949-98b5-141ee3f17458",
   "metadata": {},
   "source": [
    "### Split Documents\n",
    "\n",
    "The models have constraints on the size of individual files.  Here we want to split the PDFs into parts of no more than 1000 pages and verify that they are under 30MB in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f6f89fc-cfd4-48d6-91d4-b8ef277e5cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def doc_parts(doc):\n",
    "    start_page = 0\n",
    "    max_pages = 1000\n",
    "    n_pages = doc.page_count\n",
    "    \n",
    "    doc_list = []\n",
    "    while start_page < n_pages:\n",
    "        end_page = min(start_page + max_pages - 1, n_pages)\n",
    "        new_doc = fitz.open()\n",
    "        new_doc.insert_pdf(doc, from_page = start_page, to_page = end_page)\n",
    "        doc_list.append(new_doc)\n",
    "        start_page = end_page + 1\n",
    "    \n",
    "    print(f\"The document has {n_pages} pages and has been split into parts with page counts: {[p.page_count for p in doc_list]}\")\n",
    "    \n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4fe05d7-f1f0-4551-b828-9f2cc9682d69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document has 2641 pages and has been split into parts with page counts: [1000, 1000, 641]\n"
     ]
    }
   ],
   "source": [
    "freddie_parts = doc_parts(freddie_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa5e201b-c6cf-48ee-971c-68d15e99209d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document has 1180 pages and has been split into parts with page counts: [1000, 180]\n"
     ]
    }
   ],
   "source": [
    "fannie_parts = doc_parts(fannie_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9173f3-84b9-49a8-9e35-cdab9ec2392a",
   "metadata": {},
   "source": [
    "### Save Documents To GCS Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7b6151e-502f-4c3b-93a5-1055d0041317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def doc_to_gcs(document, name):\n",
    "    buffer = io.BytesIO()\n",
    "    document.save(buffer)\n",
    "    buffer.seek(0) # reset the position to the beginning\n",
    "    blob = bucket.blob(f\"{SERIES}/{EXPERIMENT}/{name}.pdf\")\n",
    "    blob.upload_from_file(buffer, content_type = 'application/pdf')\n",
    "    print(f\"The file 'gs://{bucket.name}/{blob.name}' is {(blob.size / (1024*1024)):.2f} MB\")\n",
    "    return blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b16bf53-7bba-42f6-996c-6fd692d79f08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/freddie_full.pdf' is 21.44 MB\n"
     ]
    }
   ],
   "source": [
    "freddie_blob = doc_to_gcs(freddie_doc, 'freddie_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a011c149-c35a-43f7-8222-c64da5b94094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/fannie_full.pdf' is 4.55 MB\n"
     ]
    }
   ],
   "source": [
    "fannie_blob = doc_to_gcs(fannie_doc, 'fannie_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76619b4-68a5-4435-9ce4-2b643a6a3c36",
   "metadata": {},
   "source": [
    "### Save Document Parts To GCS Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8788323e-4065-4d79-a9e3-fb413b128572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/freddie_part_0.pdf' is 8.45 MB\n",
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/freddie_part_1.pdf' is 7.67 MB\n",
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/freddie_part_2.pdf' is 4.59 MB\n"
     ]
    }
   ],
   "source": [
    "freddie_blobs = [doc_to_gcs(doc, f'freddie_part_{d}') for d, doc in enumerate(freddie_parts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d71dbfc-e3fd-4825-8e6d-28a3dd14122a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/fannie_part_0.pdf' is 3.49 MB\n",
      "The file 'gs://statmike-mlops-349915/applied-genai/long-context/fannie_part_1.pdf' is 0.61 MB\n"
     ]
    }
   ],
   "source": [
    "fannie_blobs = [doc_to_gcs(doc, f'fannie_part_{d}') for d, doc in enumerate(fannie_parts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391eaf3f-e5b9-483a-92b5-222c900084d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gemini Multimodal Context Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d28f3aff-74cb-443a-bfdf-be277df993ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_contexts = [\n",
    "    vertexai.generative_models.Part.from_uri(\n",
    "        uri = f\"gs://{bucket.name}/{b.name}\",\n",
    "        mime_type = b.content_type\n",
    "    ) for b in freddie_blobs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe02d334-d63d-4ef4-812d-4974fcdb6418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fannie_contexts = [\n",
    "    vertexai.generative_models.Part.from_uri(\n",
    "        uri = f\"gs://{bucket.name}/{b.name}\",\n",
    "        mime_type = b.content_type\n",
    "    ) for b in fannie_blobs\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd04e8-4ab4-4efb-ab6e-f343dea87cc8",
   "metadata": {},
   "source": [
    "### Create Context Cache(s)\n",
    "\n",
    "Rather than sending the document (parts) along with each call to the Gemini API, it can be helpful to first load the documents as a context cache.  This makes subsequent call to the API faster and possibly cheaper as the documents are charged at a caching rate (size and time used) rather than a token/character rate.  \n",
    "\n",
    "For more information on [Context Caching](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview) check out the companion workflow: [Vertex AI Gemini API](./Vertex%20AI%20Gemini%20API.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4ca7614a-e77a-4219-9dc9-641dd78608cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_cache = vertexai.preview.caching.CachedContent.create(\n",
    "    model_name = 'gemini-1.5-flash-002',\n",
    "    contents = freddie_contexts,\n",
    "    ttl = datetime.timedelta(minutes = 30)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "633f42fe-bdf6-46ff-ad1b-2cffd8345573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fannie_cache = vertexai.preview.caching.CachedContent.create(\n",
    "    model_name = 'gemini-1.5-flash-002',\n",
    "    contents = fannie_contexts,\n",
    "    ttl = datetime.timedelta(minutes = 30)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e82c5a47-5c60-41d2-b572-eef18e845477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_cache = vertexai.preview.caching.CachedContent.create(\n",
    "    model_name = 'gemini-1.5-flash-002',\n",
    "    contents = ['The Freddie Mac documents:'] + freddie_contexts + ['The Fannie Mae documents:'] + fannie_contexts,\n",
    "    system_instruction = 'You are incredibly knowledgable about GSEs (Freddie Mac and Fannie Mae) who purchase mortgages from lenders.  You answer questions about the selling process from the point of view of each GSE and then you compare/contrast each of them relative to the users question.',\n",
    "    ttl = datetime.timedelta(minutes = 30)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc10e17-7c95-4ed4-ba84-aab9fb61573f",
   "metadata": {},
   "source": [
    "### Generate Responses With Gemini Multimodal Prompts\n",
    "\n",
    "Register the Gemini Flash 1.5 model separately for each of the three caches. Then prompt each to see answer specific to Fannie Mae, Freddie Mac, and then a combined and coparative answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e314e7f-d007-4201-8492-8892fa6c0118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = 'Does a lender have to perform servicing functions directly?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59511f84-bf0e-4fd2-8c55-dfcd386ec6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freddie_model = vertexai.preview.generative_models.GenerativeModel.from_cached_content(cached_content = freddie_cache)\n",
    "fannie_model = vertexai.preview.generative_models.GenerativeModel.from_cached_content(cached_content = fannie_cache)\n",
    "combined_model = vertexai.preview.generative_models.GenerativeModel.from_cached_content(cached_content = combined_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60835287-3719-448e-989e-79c15998fedf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "No.  A lender may contract with a servicer to perform servicing functions on its behalf.  Freddie Mac's Seller/Servicer Guide outlines the responsibilities of both lenders and servicers.  The lender retains ultimate responsibility for the mortgage, but the servicer performs the day-to-day servicing activities.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freddie_response = freddie_model.generate_content(\n",
    "    contents = [prompt]\n",
    ")\n",
    "Markdown(freddie_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8efa74ae-aa7f-41ff-945c-53637bccfed3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "No.  A lender may use other organizations to perform some or all of its servicing functions (Subpart A3, Getting Started With Fannie Mae).  The Selling Guide refers to this as \"subservicing,\" meaning that a servicer (the \"subservicer\") other than the contractually responsible servicer (the \"master\" servicer) is performing the servicing functions.  However, the lender remains fully responsible to Fannie Mae for all functions that are outsourced to third parties."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fannie_response = fannie_model.generate_content(\n",
    "    contents = [prompt]\n",
    ")\n",
    "Markdown(fannie_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "653e697c-fa47-44c4-8c86-8031bfe60c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a comparison of Freddie Mac and Fannie Mae's perspectives on whether a lender must perform servicing functions directly, followed by a summary comparison:\n",
       "\n",
       "**Freddie Mac's Perspective:**\n",
       "\n",
       "Freddie Mac does *not* require lenders to perform servicing functions directly.  The *Seller/Servicer Guide* extensively covers the roles and responsibilities of both Sellers (the originating lender) and Servicers (the entity responsible for ongoing loan administration after Freddie Mac purchases the mortgage).  \n",
       "\n",
       "The guide clearly outlines scenarios where servicing is transferred to a third-party servicer, either concurrently with the sale to Freddie Mac or subsequently.  This highlights that direct servicing by the originating lender is not a mandatory requirement.  Furthermore, Freddie Mac’s *Seller/Servicer Guide* details the processes, responsibilities, and requirements related to transfers of servicing.\n",
       "\n",
       "**Fannie Mae's Perspective:**\n",
       "\n",
       "Similar to Freddie Mac, Fannie Mae also *does not* require direct servicing by the originating lender.  The *Selling Guide* outlines the roles of Sellers and Servicers, allowing for the possibility of transferring servicing rights to another Fannie Mae-approved servicer.  The guide describes the requirements for transfers of servicing in detail, emphasizing that  the lender is not required to continue servicing the loan after its sale.\n",
       "\n",
       "**Comparison:**\n",
       "\n",
       "Both Freddie Mac and Fannie Mae operate under the same fundamental principle regarding servicing:  they permit lenders to either service the loans themselves or transfer servicing rights to a third-party servicer.  Their respective guides provide comprehensive details on the procedures and requirements for both direct servicing and servicing transfers, indicating that neither GSE mandates direct servicing as a requirement for selling mortgages.  The specific requirements and processes outlined in each GSE's guide might have minor variations.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_response = combined_model.generate_content(\n",
    "    contents = [prompt]\n",
    ")\n",
    "Markdown(combined_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5463091-392f-4ece-8e93-08cf1d4a0c0f",
   "metadata": {},
   "source": [
    "### Check And Remove The Context Cache(s)\n",
    "\n",
    "Check the remaining time for each cache.  This time can be extended as needed with `.update()`.  In this case the caches are deleted to eliminate any further costs now that this workflow is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2cf54bd1-538b-4257-9f26-09314b694870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_left(cache):\n",
    "    expire = cache.expire_time\n",
    "    now = datetime.datetime.now(tz=expire.tzinfo) \n",
    "    print(f\"Expiration Time: {expire.strftime('%B %d, %Y at %I:%M:%S %p')}\")\n",
    "    print(f\"   Current Time: {now.strftime('%B %d, %Y at %I:%M:%S %p')}\")\n",
    "    diff = (expire - now).total_seconds()\n",
    "    sign, diff = (1, abs(diff)) if diff >= 0 else (-1, abs(diff))\n",
    "    minutes = int(diff // 60)\n",
    "    seconds = int(diff % 60)\n",
    "    if minutes > 60:\n",
    "        hours = int(minutes // 60)\n",
    "        minutes = minutes - hours*60\n",
    "    else: hours = 0\n",
    "    if sign == 1:\n",
    "        print(f\"{hours:02d}:{minutes:02d}:{seconds:02d} until expiration\")\n",
    "    else:\n",
    "        print(f\"Expired {hours:02d}:{minutes:02d}:{seconds:02d} ago\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a4a00d76-b9b1-44cf-9b00-165c3103d7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expiration Time: October 12, 2024 at 05:01:54 PM\n",
      "   Current Time: October 12, 2024 at 05:12:31 PM\n",
      "Expired 00:10:37 ago\n"
     ]
    }
   ],
   "source": [
    "time_left(freddie_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "34d6db5a-f93a-4ac2-bc77-57684c5049ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expiration Time: October 12, 2024 at 05:04:18 PM\n",
      "   Current Time: October 12, 2024 at 05:12:35 PM\n",
      "Expired 00:08:16 ago\n"
     ]
    }
   ],
   "source": [
    "time_left(fannie_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "475ff426-b4d6-489c-8b45-6ca286ab399d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expiration Time: October 12, 2024 at 05:06:10 PM\n",
      "   Current Time: October 12, 2024 at 05:12:36 PM\n",
      "Expired 00:06:25 ago\n"
     ]
    }
   ],
   "source": [
    "time_left(combined_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e859e36e-1386-4135-be32-7248f9d08c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(freddie_cache.list()) > 0:\n",
    "    freddie_cache.refresh\n",
    "    freddie_cache.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "66efea90-0cb9-4fbb-bfda-46b8fb303a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(fannie_cache.list()) > 0:\n",
    "    fannie_cache.refresh\n",
    "    fannie_cache.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "26ddfe33-e299-4198-b268-2d0b0c2c4b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(combined_cache.list()) > 0:\n",
    "    combiend_cache.refresh\n",
    "    combined_cache.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366be6d-a910-43e9-b0e3-c96a59ed57ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
